{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the model\n",
    "\n",
    "To understand the model it would be convenient if you have gone through demo1 and 2, however you can learn how to use the model simply reading this notebook. \n",
    "\n",
    "I will use 3 examples to illustrate the different set-ups that can be used with this pytorch implementation of wide and deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load the data\n",
    "\n",
    "Note that, as long as your dataset is in a state similar to that of `adult_data.csv` below (remove NaN, impute missing values, etc..), you are \"good to go\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DF = pd.read_csv('data/adult_data.csv')\n",
    "\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression with varying embedding dimensions, no dropout and Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1_1. Set the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a target for logistic regression:\n",
    "DF['income_label'] = (DF[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "\n",
    "# Experiment set up\n",
    "wide_cols = ['age','hours_per_week','education', 'relationship','workclass',\n",
    "             'occupation','native_country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "embeddings_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                    ('occupation',10),('native_country',10)]\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "target = 'income_label'\n",
    "method = 'logistic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1_2. prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wide_deep.data_utils import prepare_data\n",
    "\n",
    "#Â just call prepare_data\n",
    "wd_dataset = prepare_data(DF, wide_cols,crossed_cols,embeddings_cols,continuous_cols,target,scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1_3. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network set up\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=1 # for logistic and regression\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = None\n",
    "\n",
    "# Build the model. Again you just need to call WideDeep\n",
    "from wide_deep.torch_model import WideDeep\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers, dropout, encoding_dict,n_class)\n",
    "\n",
    "# I have included a compile method if you want to change the fitting method or the optimizer\n",
    "model.compile(method=method, optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1_4. Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = wd_dataset['train_dataset']\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "\n",
    "# As your usual Sklearn model, simply call fit/predict\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "pred = model.predict(dataset=test_dataset)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(pred, test_dataset.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have included a method to easily get the learned embeddings. This will return a dictionary where the keys are the column values and the values are the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_embeddings('education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiclass classification with fixed embedding dimensions (10), varying dropout and RMSProp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a feature for multiclass classification. Note that **this is only for illustration purposes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define age groups\n",
    "age_groups = [0, 25, 50, 90]\n",
    "age_labels = range(len(age_groups) - 1)\n",
    "DF['age_group'] = pd.cut(DF['age'], age_groups, labels=age_labels)\n",
    "\n",
    "# Set the experiment\n",
    "wide_cols = ['hours_per_week','education', 'relationship','workclass',\n",
    "             'occupation','native_country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "embeddings_cols = ['education', 'relationship','workclass','occupation','native_country']\n",
    "continuous_cols = [\"hours_per_week\"]\n",
    "target = 'age_group'\n",
    "method = 'multiclass'\n",
    "\n",
    "wd_dataset = prepare_data(DF,wide_cols,crossed_cols,embeddings_cols,continuous_cols,target,scale=True,def_dim=10)\n",
    "\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=3\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = [0.5, 0.2]\n",
    "\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers,dropout,encoding_dict,n_class)\n",
    "model.compile(method=method, optimizer=\"RMSprop\")\n",
    "\n",
    "# Let's have a look to the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = wd_dataset['train_dataset']\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "\n",
    "# The model object also has a predict_proba method in case you want probabilities instead of class\n",
    "pred = model.predict_proba(test_dataset)\n",
    "print('\\n {}'.format(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "print(\"\\n {}\".format(f1_score(model.predict(test_dataset), test_dataset.labels, average=\"weighted\")))\n",
    "\n",
    "print(\"\\n {}\".format(accuracy_score(model.predict(test_dataset), test_dataset.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression with varying embedding dimensions and varying dropout.\n",
    "\n",
    "Again, bear in mind that here we use `age` as target just **for illustration purposes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment\n",
    "wide_cols = ['hours_per_week','education', 'relationship','workclass',\n",
    "             'occupation','native_country','gender']\n",
    "crossed_cols  = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "embeddings_cols  = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                    ('occupation',10),('native_country',10)]\n",
    "continuous_cols = [\"hours_per_week\"]\n",
    "target = 'age'\n",
    "method = 'regression'\n",
    "\n",
    "# Prepare the dataset\n",
    "wd_dataset = prepare_data(DF, wide_cols,crossed_cols,embeddings_cols,continuous_cols,target)\n",
    "\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=1\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = [0.5, 0.2]\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers,dropout,encoding_dict,n_class)\n",
    "model.compile(method=method)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = wd_dataset['train_dataset']\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "pred = model.predict(test_dataset)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"\\n RMSE: {}\".format(np.sqrt(mean_squared_error(pred, test_dataset.labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
