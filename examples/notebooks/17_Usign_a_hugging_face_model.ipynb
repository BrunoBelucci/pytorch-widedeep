{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1aa10",
   "metadata": {},
   "source": [
    "In this notebook we will show how to use a Hugginface model using this library along with any other model in the libray. In particular we will show how to combine it with a tabular DL model.\n",
    "\n",
    "Since we are here, we will also compare the performance of a few models on a text classification problem. \n",
    "\n",
    "Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75756db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import Dataset as lgbDataset\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.models import BasicRNN, WideDeep\n",
    "from pytorch_widedeep.metrics import F1Score, Accuracy\n",
    "from pytorch_widedeep.utils import Tokenizer, LabelEncoder\n",
    "from pytorch_widedeep.preprocessing import TextPreprocessor\n",
    "from pytorch_widedeep.datasets import load_womens_ecommerce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4b786",
   "metadata": {},
   "source": [
    "Let's load the data and have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6f1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_womens_ecommerce(as_frame=True)\n",
    "\n",
    "df.columns = [c.replace(\" \", \"_\").lower() for c in df.columns]\n",
    "\n",
    "# classes from [0,num_class)\n",
    "df[\"rating\"] = (df[\"rating\"] - 1).astype(\"int64\")\n",
    "\n",
    "# group reviews with 1 and 2 scores into one class\n",
    "df.loc[df.rating == 0, \"rating\"] = 1\n",
    "\n",
    "# and back again to [0,num_class)\n",
    "df[\"rating\"] = (df[\"rating\"] - 1).astype(\"int64\")\n",
    "\n",
    "# drop short reviews\n",
    "df = df[~df.review_text.isna()]\n",
    "df[\"review_length\"] = df.review_text.apply(lambda x: len(x.split(\" \")))\n",
    "df = df[df.review_length >= 5]\n",
    "df = df.drop(\"review_length\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f518da68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>positive_feedback_count</th>\n",
       "      <th>division_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>None</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  age                    title  \\\n",
       "0          767   33                     None   \n",
       "1         1080   34                     None   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         review_text  rating  recommended_ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       2                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       3                1   \n",
       "2  I had such high hopes for this dress and reall...       1                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       3                1   \n",
       "4  This shirt is very flattering to all due to th...       3                1   \n",
       "\n",
       "   positive_feedback_count   division_name department_name class_name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cc2c8",
   "metadata": {},
   "source": [
    "So, we will use the `review_text` column to predict the `rating`. Later on, we will try to combine it with some other columns (like `division_name` and `age`) see if these help.\n",
    "\n",
    "Let's first have a look to the distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba88f4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    12515\n",
       "2     4904\n",
       "1     2820\n",
       "0     2369\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e55b1",
   "metadata": {},
   "source": [
    "This shows that we could have perhaps grouped rating scores of 1, 2 and 3 into 1...but anyway, let's just move on with those 4 classes.\n",
    "\n",
    "We are not going to carry any hyperparameter optimization here, so, we will only need a train and a test set (i.e.  no need of a validation set for the example in this notebook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df254871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size=0.8, random_state=1, stratify=df.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e3fc1",
   "metadata": {},
   "source": [
    "Let's see what we have to beat. What metrics would we obtain if we always predict the most common rating (3)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428ad14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_pred = [train.rating.value_counts().index[0]] * len(test)\n",
    "\n",
    "most_common_acc = accuracy_score(test.rating, most_common_pred)\n",
    "most_common_f1 = f1_score(test.rating, most_common_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f116d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.553516143299425. F1 Score: 0.3944344218301668\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {most_common_acc}. F1 Score: {most_common_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0a6a2",
   "metadata": {},
   "source": [
    "ok, these are our \"baseline\" metrics. \n",
    "\n",
    "Let's start by using simply tf-idf + lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b144f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this Tokenizer is part of our utils module but of course, any valid tokenizer can be used here\n",
    "tok = Tokenizer()\n",
    "tok_reviews_tr = tok.process_all(train.review_text.tolist())\n",
    "tok_reviews_te = tok.process_all(test.review_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa94f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, preprocessor=lambda x: x, tokenizer=lambda x: x, min_df=5\n",
    ")\n",
    "\n",
    "X_text_tr = vectorizer.fit_transform(tok_reviews_tr)\n",
    "X_text_te = vectorizer.transform(tok_reviews_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5809e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18086x4566 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 884074 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cb754",
   "metadata": {},
   "source": [
    "We now move our matrices to lightGBM `Dataset` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c88b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbtrain_text = lgbDataset(\n",
    "    X_text_tr,\n",
    "    train.rating.values,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "lgbtest_text = lgbDataset(\n",
    "    X_text_te,\n",
    "    test.rating.values,\n",
    "    reference=lgbtrain_text,\n",
    "    free_raw_data=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb88ed",
   "metadata": {},
   "source": [
    "and off we go. By the way, I think as we run the next cell, we should appreciate how fast lightGBM runs. Yes, the input is a sparse matrix, but still, trains on 18086x4566 in a matter of secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582c6efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143330\n",
      "[LightGBM] [Info] Number of data points in the train set: 18086, number of used features: 2285\n",
      "[LightGBM] [Info] Start training from score -2.255919\n",
      "[LightGBM] [Info] Start training from score -2.081545\n",
      "[LightGBM] [Info] Start training from score -1.528281\n",
      "[LightGBM] [Info] Start training from score -0.591354\n"
     ]
    }
   ],
   "source": [
    "model_text = lgb.train(\n",
    "    {\"objective\": \"multiclass\", \"num_classes\": 4},\n",
    "    lgbtrain_text,\n",
    "    valid_sets=[lgbtest_text, lgbtrain_text],\n",
    "    valid_names=[\"test\", \"train\"],\n",
    "    verbose_eval=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e5462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = model_text.predict(X_text_te)\n",
    "pred_text_class = np.argmax(preds_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "143f61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_text = accuracy_score(lgbtest_text.label, pred_text_class)\n",
    "f1_text = f1_score(lgbtest_text.label, pred_text_class, average=\"weighted\")\n",
    "cm_text = confusion_matrix(lgbtest_text.label, pred_text_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7cb8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6444051304732419, 0.617154488246181)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_text, f1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15397539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 199,  135,   61,   79],\n",
       "       [ 123,  169,  149,  123],\n",
       "       [  30,   94,  279,  578],\n",
       "       [  16,   30,  190, 2267]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec73328",
   "metadata": {},
   "source": [
    "Ok, so, with no hyperparameter optimization lightGBM gets an accuracy of 0.64 and a F1 score of 0.62, cool, significantly better than predicting always the most popular. \n",
    "\n",
    "Let's see if in this implementation, some additional features, like `age` or `class_name` are of any help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bdc37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_cols = [\n",
    "    \"age\",\n",
    "    \"division_name\",\n",
    "    \"department_name\",\n",
    "    \"class_name\",\n",
    "]\n",
    "\n",
    "for tab_df in [train, test]:\n",
    "    for c in [\"division_name\", \"department_name\", \"class_name\"]:\n",
    "        tab_df[c] = tab_df[c].str.lower()\n",
    "        tab_df[c].fillna(\"missing\", inplace=True)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b17aa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our LabelEncoder. A class that is designed to work with the models in this library but \n",
    "# can be used for general purposes\n",
    "le = LabelEncoder(columns_to_encode=[\"division_name\", \"department_name\", \"class_name\"])\n",
    "train_tab_le = le.fit_transform(train)\n",
    "test_tab_le = le.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e55e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>positive_feedback_count</th>\n",
       "      <th>division_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>836</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>Bought this on sale in my reg size- 10. im 5'9...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>1022</td>\n",
       "      <td>25</td>\n",
       "      <td>Look like \"mom jeans\"</td>\n",
       "      <td>Maybe i just have the wrong body type for thes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>815</td>\n",
       "      <td>39</td>\n",
       "      <td>Ig brought me here</td>\n",
       "      <td>Love the way this top layers under my jackets ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12132</th>\n",
       "      <td>984</td>\n",
       "      <td>47</td>\n",
       "      <td>Runs small especially the arms</td>\n",
       "      <td>I love this jacket. it's the prettiest and mos...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20756</th>\n",
       "      <td>1051</td>\n",
       "      <td>42</td>\n",
       "      <td>True red, true beauty.</td>\n",
       "      <td>These pants are gorgeous--the fabric has a sat...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clothing_id  age                           title  \\\n",
       "4541           836   35                            None   \n",
       "18573         1022   25           Look like \"mom jeans\"   \n",
       "1058           815   39              Ig brought me here   \n",
       "12132          984   47  Runs small especially the arms   \n",
       "20756         1051   42          True red, true beauty.   \n",
       "\n",
       "                                             review_text  rating  \\\n",
       "4541   Bought this on sale in my reg size- 10. im 5'9...       2   \n",
       "18573  Maybe i just have the wrong body type for thes...       1   \n",
       "1058   Love the way this top layers under my jackets ...       2   \n",
       "12132  I love this jacket. it's the prettiest and mos...       3   \n",
       "20756  These pants are gorgeous--the fabric has a sat...       3   \n",
       "\n",
       "       recommended_ind  positive_feedback_count  division_name  \\\n",
       "4541                 1                        2              1   \n",
       "18573                0                        0              2   \n",
       "1058                 1                        0              1   \n",
       "12132                1                        0              1   \n",
       "20756                1                        0              2   \n",
       "\n",
       "       department_name  class_name  \n",
       "4541                 1           1  \n",
       "18573                2           2  \n",
       "1058                 1           1  \n",
       "12132                3           3  \n",
       "20756                2           4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tab_le.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326c0de",
   "metadata": {},
   "source": [
    "let's for example have a look to the encodings for the categorical feature `class_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de0cb90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blouses': 1,\n",
       " 'jeans': 2,\n",
       " 'jackets': 3,\n",
       " 'pants': 4,\n",
       " 'knits': 5,\n",
       " 'dresses': 6,\n",
       " 'skirts': 7,\n",
       " 'sweaters': 8,\n",
       " 'fine gauge': 9,\n",
       " 'legwear': 10,\n",
       " 'lounge': 11,\n",
       " 'shorts': 12,\n",
       " 'outerwear': 13,\n",
       " 'intimates': 14,\n",
       " 'swim': 15,\n",
       " 'trend': 16,\n",
       " 'sleep': 17,\n",
       " 'layering': 18,\n",
       " 'missing': 19,\n",
       " 'casual bottoms': 20,\n",
       " 'chemises': 21}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.encoding_dict['class_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b365c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular training and test sets\n",
    "X_tab_tr = csr_matrix(train_tab_le[tab_cols].values)\n",
    "X_tab_te = csr_matrix(test_tab_le[tab_cols].values)\n",
    "\n",
    "# text + tabular training and test sets\n",
    "X_tab_text_tr = hstack((X_tab_tr, X_text_tr))\n",
    "X_tab_text_va = hstack((X_tab_te, X_text_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c074b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18086x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 72344 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tab_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f35351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18086x4570 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 956418 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tab_text_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d396b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbtrain_tab_text = lgbDataset(\n",
    "    X_tab_text_tr,\n",
    "    train.rating.values,\n",
    "    categorical_feature=[0, 1, 2, 3],\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "lgbtest_tab_text = lgbDataset(\n",
    "    X_tab_text_va,\n",
    "    test.rating.values,\n",
    "    reference=lgbtrain_tab_text,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a36cd21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 1, 2, 3]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143432\n",
      "[LightGBM] [Info] Number of data points in the train set: 18086, number of used features: 2289\n",
      "[LightGBM] [Info] Start training from score -2.255919\n",
      "[LightGBM] [Info] Start training from score -2.081545\n",
      "[LightGBM] [Info] Start training from score -1.528281\n",
      "[LightGBM] [Info] Start training from score -0.591354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/javierrodriguezzaurin/.pyenv/versions/3.8.12/envs/widedeep38/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "model_tab_text = lgb.train(\n",
    "    {\"objective\": \"multiclass\", \"num_classes\": 4},\n",
    "    lgbtrain_tab_text,\n",
    "    valid_sets=[lgbtrain_tab_text, lgbtest_tab_text],\n",
    "    valid_names=[\"test\", \"train\"],\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbaf5d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tab_text = model_tab_text.predict(X_tab_text_va)\n",
    "preds_tab_text_class = np.argmax(preds_tab_text, 1)\n",
    "\n",
    "acc_tab_text = accuracy_score(lgbtest_tab_text.label, preds_tab_text_class)\n",
    "f1_tab_text = f1_score(lgbtest_tab_text.label, preds_tab_text_class, average=\"weighted\")\n",
    "cm_tab_text = confusion_matrix(lgbtest_tab_text.label, preds_tab_text_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9bd76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6382131800088456, 0.6080251307242649)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_tab_text, f1_tab_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29bc8ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 193,  123,   68,   90],\n",
       "       [ 123,  146,  157,  138],\n",
       "       [  37,   90,  272,  582],\n",
       "       [  16,   37,  175, 2275]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_tab_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc093906",
   "metadata": {},
   "source": [
    "Ok, so, in this set up, addition, tabular columns do not help performance, in fact, the opposite.\n",
    "\n",
    "Moving on now to fully using `pytorch-widedeep` in this dataset, let's have a look on how one could use a simple RNN to predict the ratings with the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f7b9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 4328 tokens\n"
     ]
    }
   ],
   "source": [
    "text_preprocessor = TextPreprocessor(\n",
    "    text_col=\"review_text\", max_vocab=5000, min_freq=5, maxlen=90, n_cpus=1\n",
    ")\n",
    "\n",
    "X_text_tr = text_preprocessor.fit_transform(train)\n",
    "X_text_te = text_preprocessor.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d03daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rnn = BasicRNN(\n",
    "    vocab_size=len(text_preprocessor.vocab.itos),\n",
    "    embed_dim=300,\n",
    "    hidden_dim=64,\n",
    "    n_layers=3,\n",
    "    rnn_dropout=0.2,\n",
    "    head_hidden_dims=[32],\n",
    ")\n",
    "\n",
    "\n",
    "model = WideDeep(deeptext=basic_rnn, pred_dim=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b22d4c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (deeptext): Sequential(\n",
       "    (0): BasicRNN(\n",
       "      (word_embed): Embedding(4328, 300, padding_idx=1)\n",
       "      (rnn): LSTM(300, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
       "      (rnn_mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (dense_layer_0): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=32, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84b14833",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=\"multiclass\",\n",
    "    metrics=[Accuracy, F1Score(average=True)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d162b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1:   0%|                                                                                                          | 0/71 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    X_text=X_text_tr,\n",
    "    target=train.rating.values,\n",
    "    n_epochs=5,\n",
    "    batch_size=256,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
