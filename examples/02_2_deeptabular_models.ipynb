{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `deeptabular` component\n",
    "\n",
    "In the previous notebook I described the linear model (`Wide`) and the standard text classification and regression models (`DeepText` and `DeepImage`) that can be used as the `wide`, `deeptext` and `deepimage` components respectively when building a `WideDeep` model. \n",
    "\n",
    "In this notebook I will describe the 3 models (or architectures) available in `pytorch-widedeep` that can be used as the `deeptabular` model. Note that the `deeptabular` model alone is what normally would be referred as Deep Learning for tabular data. As I mentioned in previous notebooks, each component can be used independently. Therefore, if you wanted to use `deeptabular` alone it is perfectly possible. There are just a couple of simple requirement that will be covered in a later notebook.\n",
    "\n",
    "The 3 models available in `pytorch-widedeep` as the `deeptabular` are:\n",
    "\n",
    "1. `TabMlp`\n",
    "2. `TabResnet`\n",
    "3. `TabTransformer`\n",
    "\n",
    "Let's have a close look to the 3 of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `TabMlp`\n",
    "\n",
    "`TabMlp` is the simples architecture and is very similar to the tabular model available in the fantastic fastai library. In fact, the implementation of the dense layers of the MLP is mostly identical to that in that library.\n",
    "\n",
    "The figure below illustrate the `TabMlp` architecture:\n",
    "\n",
    "<img src=\"../docs/figures/tabmlp_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "The dashed-border boxes indicate that these components are optional. For example, we could use `TabMlp` without categorical components, or without continuous components, if we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier/.pyenv/versions/3.7.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_widedeep.models import TabMlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabMlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to a model and one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tabmlp = TabMlp(mlp_hidden_dims=[8,4], continuous_cols=['e'], column_idx=column_idx, \n",
    "                embed_input=embed_input, batchnorm_cont=True)\n",
    "out = tabmlp(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabMlp(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tab_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=33, out_features=8, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabmlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input dimension of the MLP is `33`, `32` from the embeddings and `1` for the continuous features. Before we move on, is worth commenting an aspect that applies to the three models discussed here. The `TabPreprocessor` included in this package gives the user the possibility of standarising the input via `sklearn`'s `StandardScaler`. Alternatively, or in addition to it, it is possible to add a `BatchNorm1d` layer to normalise continuous columns within `TabMlp`. To do so simply set the `batchnorm_cont` parameter as `True` when defining the model, as indicated in the example above.\n",
    "\n",
    "I will insist on this in this and the following sections. Note that `TabMlp` (or any of the wide and deep components) does not build the final connection with the final neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import WideDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_model = WideDeep(deeptabular=tabmlp, pred_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabMlp(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "      )\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tab_mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (dense_layer_0): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=33, out_features=8, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (dense_layer_1): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=8, out_features=4, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `TabResnet`\n",
    "\n",
    "`TabResnet` is very similar to `TabMlp`, but the embeddings (or the concatenation of embeddings and continuous features) are passed through a series of Resnet blocks built with dense layers. This is probably the most flexible `deeptabular` component in terms of the many variants one can define via the parameters. Let's have a look to the architecture:\n",
    "\n",
    "<img src=\"../docs/figures/tabresnet_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "The dashed-border boxes indicate the the component is optional and the dashed lines indicate the different paths or connections present depending on which components we decide to include. For example, we could chose to concatenate the continuous features, normalized or not via a `BatchNorm1d` layer, with the embeddings and pass the result of such a concatenation trough the series of Resnet blocks. Alternatively, we might prefer to concatenate the continuous features with the results of passing the embeddings through the Resnet blocks. Another optional component is the MLP before the output neuron(s). If not MLP is present, the output from the Resnet blocks or the results of concatenating that output with the continuous features (normalised or not) will be connected directly to the output neuron(s). \n",
    "\n",
    "Each Resnet block is comprised by the following operations:\n",
    "\n",
    "<img src=\"../docs/figures/resnet_block.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "For more details see [`pytorch_widedeep/models/tab_resnet.BasicBlock`](https://github.com/jrzaurin/pytorch-widedeep/blob/master/pytorch_widedeep/models/tab_resnet.py). \n",
    "\n",
    "Let's have a look to an example now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tabresnet = TabResnet(blocks_dims=[16,16,16], \n",
    "                  column_idx=column_idx, \n",
    "                  embed_input=embed_input,\n",
    "                  continuous_cols = ['e'],\n",
    "                  batchnorm_cont = True,\n",
    "                  concat_cont_first = False, \n",
    "                  mlp_hidden_dims = [16, 4],\n",
    "                  mlp_dropout = 0.5)\n",
    "out = tabresnet(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabResnet(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tab_resnet_blks): DenseResnet(\n",
       "    (dense_resnet): Sequential(\n",
       "      (lin1): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (block_0): BasicBlock(\n",
       "        (lin1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block_1): BasicBlock(\n",
       "        (lin1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tab_resnet_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=17, out_features=16, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabresnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, first the embeddings are concatenated (resulting in a tensor of dim ($*$, 32) and are projected (or resized, which happens in `lin1` and `bn1`) to the input dimension of the Resnet block (16). The we have the two Resnet blocks defined by the sequence `[INP1 (16) -> OUT1 == INP2 (16) -> OUT2 (16)]`. Finally the output from the Resnet blocks is concatenated and passed to the MLP. \n",
    "\n",
    "As I mentioned earlier, note that `TabResnet` does not build the connection to the output neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. `TabTransformer`\n",
    "\n",
    "Details on this architecture can be found in [TabTransformer: Tabular Data Modeling\n",
    "Using Contextual Embeddings](https://arxiv.org/pdf/2012.06678.pdf). Also, there are so many variants and details that I thought it deserves its own post. Therefore, if you want to dive properly into the use of the Transformer for tabular data I recommend to read the paper and the post (probably in that order). \n",
    "\n",
    "In general terms, `TabTransformer` takes the embeddings from the categorical columns that are then passed through a Tranformer encoder, concatenated with the normalised continuous features, and then passed through an MLP. Let's have a look:\n",
    "\n",
    "<img src=\"../docs/figures/tabtransformer_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "\n",
    "The dashed-border boxes indicate the the component is optional. In terms of the Transformer block, I am sure at this stage the reader has seen every possible diagram of The Transformer, its multihead attention etc, so I thought about drawing something that resembles more to the actual execution/code for each block. \n",
    "\n",
    "<img src=\"../docs/figures/transformer_block.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "Note that this implementation assumes that the so called `inner-dim` (aka the projection dimension) is the same as the `dimension of the model` or, in this case, embedding dimension. Relaxing this assumption is relatively easy and programatically would involve including one parameter more in the `TabTransformer` class. For now, and consistent with other Transformer implementations, I will assume `inner-dim = dimension of the model`. Also, and again consistent other implementations, I assume that the Keys, Queries and Values are of the same `dim`. \n",
    "\n",
    "Enough writing, let's have a look to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i) for u,i in zip(colnames[:4], [4]*4)]\n",
    "continuous_cols = ['e']\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tab_transformer = TabTransformer(column_idx=column_idx, embed_input=embed_input, continuous_cols=continuous_cols)\n",
    "out = tab_transformer(X_tab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (emb_layer_a): Embedding(5, 32, padding_idx=0)\n",
       "    (emb_layer_b): Embedding(5, 32, padding_idx=0)\n",
       "    (emb_layer_c): Embedding(5, 32, padding_idx=0)\n",
       "    (emb_layer_d): Embedding(5, 32, padding_idx=0)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (tab_transformer_blks): Sequential(\n",
       "    (block0): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tab_transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=129, out_features=516, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=516, out_features=258, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I have used the parameters that are suggested in the paper, or those used in the AutoGluon implementation.\n",
    "\n",
    "Finally, and as I mentioned earlier, note that `TabTransformer` does not build the connection to the output neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
