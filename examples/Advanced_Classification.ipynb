{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, DeepPreprocessor\n",
    "from pytorch_widedeep.models import Wide, DeepDense, WideDeep\n",
    "from pytorch_widedeep.optim import RAdam\n",
    "from pytorch_widedeep.initializers import KaimingNormal, XavierNormal\n",
    "from pytorch_widedeep.callbacks import LRHistory, ModelCheckpoint, EarlyStopping\n",
    "from pytorch_widedeep.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (wide): Wide(\n",
       "    (wide_linear): Linear(in_features=805, out_features=1, bias=True)\n",
       "  )\n",
       "  (deepdense): Sequential(\n",
       "    (0): DeepDense(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_education): Embedding(16, 10)\n",
       "        (emb_layer_native_country): Embedding(42, 10)\n",
       "        (emb_layer_occupation): Embedding(15, 10)\n",
       "        (emb_layer_relationship): Embedding(6, 8)\n",
       "        (emb_layer_workclass): Embedding(9, 10)\n",
       "      )\n",
       "      (dense): Sequential(\n",
       "        (dense_layer_0): Sequential(\n",
       "          (0): Linear(in_features=50, out_features=64, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (dense_layer_1): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (2): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/adult/adult.csv.zip')\n",
    "df.columns = [c.replace(\"-\", \"_\") for c in df.columns]\n",
    "df['age_buckets'] = pd.cut(df.age, bins=[16, 25, 30, 35, 40, 45, 50, 55, 60, 91], labels=np.arange(9))\n",
    "df['income_label'] = (df[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df.drop('income', axis=1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "wide_cols = ['age_buckets', 'education', 'relationship','workclass','occupation',\n",
    "    'native_country','gender']\n",
    "crossed_cols = [('education', 'occupation'), ('native_country', 'occupation')]\n",
    "cat_embed_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "    ('occupation',10),('native_country',10)]\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "target = 'income_label'\n",
    "\n",
    "target = df[target].values\n",
    "prepare_wide = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = prepare_wide.fit_transform(df)\n",
    "prepare_deep = DeepPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_deep = prepare_deep.fit_transform(df)\n",
    "wide = Wide(wide_dim=X_wide.shape[1], output_dim=1)\n",
    "deepdense = DeepDense(hidden_layers=[64,32], dropout=[0.5],\n",
    "                      deep_column_idx=prepare_deep.deep_column_idx,\n",
    "                      embed_input=prepare_deep.embeddings_input,\n",
    "                      continuous_cols=continuous_cols)\n",
    "model = WideDeep(wide=wide, deepdense=deepdense)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_opt = torch.optim.Adam(model.wide.parameters())\n",
    "deep_opt = RAdam(model.deepdense.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=3)\n",
    "deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializers = {'wide': KaimingNormal, 'deepdense':XavierNormal}\n",
    "optimizers = {'wide': wide_opt, 'deepdense':deep_opt}\n",
    "schedulers = {'wide': wide_sch, 'deepdense':deep_sch}\n",
    "callbacks = [LRHistory, EarlyStopping, ModelCheckpoint(filepath='../model_weights/wd_out')]\n",
    "metrics = [BinaryAccuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(method='logistic', initializers=initializers, optimizers=optimizers, lr_schedulers=schedulers,\n",
    "              callbacks=callbacks, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 153/153 [00:01<00:00, 90.38it/s, loss=0.554, metrics={'acc': 0.7213}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 143.57it/s, loss=0.45, metrics={'acc': 0.7365}]\n",
      "epoch 2: 100%|██████████| 153/153 [00:01<00:00, 99.12it/s, loss=0.403, metrics={'acc': 0.8173}] \n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 137.70it/s, loss=0.382, metrics={'acc': 0.8183}]\n",
      "epoch 3: 100%|██████████| 153/153 [00:01<00:00, 97.10it/s, loss=0.368, metrics={'acc': 0.8321}] \n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 142.64it/s, loss=0.365, metrics={'acc': 0.8319}]\n",
      "epoch 4: 100%|██████████| 153/153 [00:01<00:00, 97.67it/s, loss=0.356, metrics={'acc': 0.8356}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 139.90it/s, loss=0.358, metrics={'acc': 0.8354}]\n",
      "epoch 5: 100%|██████████| 153/153 [00:01<00:00, 98.53it/s, loss=0.351, metrics={'acc': 0.8373}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 142.39it/s, loss=0.355, metrics={'acc': 0.8368}]\n",
      "epoch 6: 100%|██████████| 153/153 [00:01<00:00, 96.25it/s, loss=0.349, metrics={'acc': 0.8398}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 128.13it/s, loss=0.354, metrics={'acc': 0.8392}]\n",
      "epoch 7: 100%|██████████| 153/153 [00:01<00:00, 95.02it/s, loss=0.347, metrics={'acc': 0.8399}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 122.67it/s, loss=0.353, metrics={'acc': 0.8389}]\n",
      "epoch 8: 100%|██████████| 153/153 [00:01<00:00, 93.82it/s, loss=0.346, metrics={'acc': 0.8395}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 139.97it/s, loss=0.353, metrics={'acc': 0.8387}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/javier/pytorch-widedeep/pytorch_widedeep/callbacks.py(338)on_epoch_end()\n",
      "-> if self.wait >= self.patience:\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 153/153 [00:01<00:00, 91.56it/s, loss=0.347, metrics={'acc': 0.8401}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 125.78it/s, loss=0.353, metrics={'acc': 0.8392}]\n",
      "epoch 10: 100%|██████████| 153/153 [00:01<00:00, 93.83it/s, loss=0.346, metrics={'acc': 0.8406}]\n",
      "valid: 100%|██████████| 39/39 [00:00<00:00, 138.04it/s, loss=0.351, metrics={'acc': 0.8399}]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_wide=X_wide, X_deep=X_deep, target=target, n_epochs=10, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.554220751804464,\n",
       "  0.40329983148699494,\n",
       "  0.3677725032264111,\n",
       "  0.3562958643716924,\n",
       "  0.35065410904635014,\n",
       "  0.34857911046813517,\n",
       "  0.34745271260442295,\n",
       "  0.34648635554936974,\n",
       "  0.34684639136775647,\n",
       "  0.34612662651959586],\n",
       " 'train_acc': [0.7213,\n",
       "  0.8173,\n",
       "  0.8321,\n",
       "  0.8356,\n",
       "  0.8373,\n",
       "  0.8398,\n",
       "  0.8399,\n",
       "  0.8395,\n",
       "  0.8401,\n",
       "  0.8406],\n",
       " 'val_loss': [0.45026036103566486,\n",
       "  0.3821376669101226,\n",
       "  0.36544298820006543,\n",
       "  0.3581323524316152,\n",
       "  0.3551228948128529,\n",
       "  0.35395471866314226,\n",
       "  0.3530398324514047,\n",
       "  0.35306169665776765,\n",
       "  0.352843076754839,\n",
       "  0.3511059482892354],\n",
       " 'val_acc': [0.7365,\n",
       "  0.8183,\n",
       "  0.8319,\n",
       "  0.8354,\n",
       "  0.8368,\n",
       "  0.8392,\n",
       "  0.8389,\n",
       "  0.8387,\n",
       "  0.8392,\n",
       "  0.8399]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history._history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_wide_0': [0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  1.0000000000000003e-05,\n",
       "  1.0000000000000003e-05,\n",
       "  1.0000000000000003e-05,\n",
       "  1.0000000000000002e-06,\n",
       "  1.0000000000000002e-06],\n",
       " 'lr_deepdense_0': [0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  0.0001,\n",
       "  1.0000000000000003e-05]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lr_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
